{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTx_tZEFPqgw"
      },
      "outputs": [],
      "source": [
        "!pip install anomalib[full]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQkNLlAQPtQ1",
        "outputId": "d4b5cc93-b44c-4db1-ae4a-76e6dc592e3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/openvino/runtime/__init__.py:10: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from typing import Any\n",
        "import time\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToPILImage\n",
        "import pandas as pd\n",
        "\n",
        "from anomalib.data import MVTecAD\n",
        "from anomalib.data.utils import read_image\n",
        "from anomalib.deploy import ExportType, OpenVINOInferencer\n",
        "from anomalib.engine import Engine\n",
        "from anomalib.models import EfficientAd\n",
        "from anomalib.utils.visualization import ImageResult\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr64scU2X7Mu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import contextlib\n",
        "from anomalib.data import MVTecAD\n",
        "from anomalib.models import EfficientAd\n",
        "from pytorch_lightning import Trainer\n",
        "from statistics import mean\n",
        "\n",
        "# Categories from MVTec AD\n",
        "categories = [\n",
        "    'bottle', 'cable', 'capsule', 'carpet', 'grid',\n",
        "    'hazelnut', 'leather', 'metal_nut', 'pill', 'screw',\n",
        "    'tile', 'toothbrush', 'transistor', 'wood', 'zipper'\n",
        "]\n",
        "\n",
        "# To store results\n",
        "all_results = []\n",
        "\n",
        "# Helper to suppress output\n",
        "@contextlib.contextmanager\n",
        "def suppress_output():\n",
        "    with open(os.devnull, \"w\") as devnull:\n",
        "        with contextlib.redirect_stdout(devnull), contextlib.redirect_stderr(devnull):\n",
        "            yield\n",
        "\n",
        "with suppress_output():\n",
        "\n",
        "    # Training loop\n",
        "    for category in categories:\n",
        "        print(f\"Processing category: {category}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        datamodule = MVTecAD(\n",
        "            root='./datasets/MVTecAD',\n",
        "            category=category,\n",
        "            train_batch_size=1,\n",
        "            eval_batch_size=1,\n",
        "            num_workers=2,\n",
        "        )\n",
        "\n",
        "        datamodule.prepare_data()\n",
        "        datamodule.setup()\n",
        "\n",
        "        model = EfficientAd()\n",
        "\n",
        "        engine = Engine(\n",
        "            max_epochs = 10,\n",
        "            accelerator=\"auto\",  # \\<\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\">,\n",
        "            devices=1,\n",
        "            logger=False,\n",
        "        )\n",
        "\n",
        "        engine.fit(model, datamodule=datamodule)\n",
        "        result = engine.test(model, datamodule=datamodule)\n",
        "\n",
        "        result = result[0]\n",
        "        latency = time.time() - start_time\n",
        "        result[\"category\"] = category\n",
        "        result[\"latency_sec\"] = round(latency, 2)\n",
        "\n",
        "        all_results.append(result)\n",
        "\n",
        "# Compute averages\n",
        "avg_metrics = {\n",
        "    \"image_AUROC\": mean([r[\"image_AUROC\"] for r in all_results]),\n",
        "    \"image_F1Score\": mean([r[\"image_F1Score\"] for r in all_results]),\n",
        "    \"latency_sec\": mean([r[\"latency_sec\"] for r in all_results])\n",
        "}\n",
        "\n",
        "# Display summary\n",
        "print(\"\\nPer-Category Results:\")\n",
        "for r in all_results:\n",
        "    print(f\"{r['category']:12s} | \"\n",
        "          f\"Image AUROC: {r['image_AUROC']:.4f} | \"\n",
        "          f\"Image F1: {r['image_F1Score']:.4f} | \"\n",
        "          f\"Latency: {r['latency_sec']}s\")\n",
        "\n",
        "print(\"\\nAverage Metrics:\")\n",
        "for k, v in avg_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFzDJkNKeklr",
        "outputId": "65576dac-7fcd-4108-87ff-cc7010393026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Per-Category Results:\n",
            "bottle       | Image AUROC: 1.0000 | Image F1: 0.9920 | Pixel AUROC: 0.9676 | Pixel F1: 0.7416 | Latency: 865.41s\n",
            "cable        | Image AUROC: 0.9108 | Image F1: 0.8804 | Pixel AUROC: 0.9504 | Pixel F1: 0.5881 | Latency: 597.44s\n",
            "capsule      | Image AUROC: 0.5975 | Image F1: 0.9030 | Pixel AUROC: 0.9083 | Pixel F1: 0.2462 | Latency: 558.43s\n",
            "carpet       | Image AUROC: 0.9928 | Image F1: 0.9773 | Pixel AUROC: 0.9589 | Pixel F1: 0.6813 | Latency: 630.7s\n",
            "grid         | Image AUROC: 0.9841 | Image F1: 0.9821 | Pixel AUROC: 0.9229 | Pixel F1: 0.4849 | Latency: 506.09s\n",
            "hazelnut     | Image AUROC: 0.8296 | Image F1: 0.8400 | Pixel AUROC: 0.7892 | Pixel F1: 0.4989 | Latency: 802.34s\n",
            "leather      | Image AUROC: 0.9178 | Image F1: 0.9130 | Pixel AUROC: 0.9588 | Pixel F1: 0.5503 | Latency: 569.69s\n",
            "metal_nut    | Image AUROC: 0.9541 | Image F1: 0.9418 | Pixel AUROC: 0.9409 | Pixel F1: 0.7638 | Latency: 462.25s\n",
            "pill         | Image AUROC: 0.9015 | Image F1: 0.9298 | Pixel AUROC: 0.9391 | Pixel F1: 0.5887 | Latency: 610.43s\n",
            "screw        | Image AUROC: 0.6627 | Image F1: 0.8625 | Pixel AUROC: 0.9646 | Pixel F1: 0.2943 | Latency: 676.9s\n",
            "tile         | Image AUROC: 0.9964 | Image F1: 0.9765 | Pixel AUROC: 0.8846 | Pixel F1: 0.6803 | Latency: 512.34s\n",
            "toothbrush   | Image AUROC: 0.6694 | Image F1: 0.8358 | Pixel AUROC: 0.9073 | Pixel F1: 0.2692 | Latency: 175.29s\n",
            "transistor   | Image AUROC: 0.6904 | Image F1: 0.6140 | Pixel AUROC: 0.8599 | Pixel F1: 0.4413 | Latency: 512.12s\n",
            "wood         | Image AUROC: 0.9781 | Image F1: 0.9580 | Pixel AUROC: 0.8213 | Pixel F1: 0.4830 | Latency: 528.64s\n",
            "zipper       | Image AUROC: 0.9091 | Image F1: 0.9590 | Pixel AUROC: 0.9426 | Pixel F1: 0.6002 | Latency: 535.9s\n",
            "\n",
            "Average Metrics:\n",
            "image_AUROC: 0.8663\n",
            "image_F1Score: 0.9043\n",
            "latency_sec: 569.5980\n"
          ]
        }
      ],
      "source": [
        "# Display summary\n",
        "print(\"\\nPer-Category Results:\")\n",
        "for r in all_results:\n",
        "    print(f\"{r['category']:12s} | \"\n",
        "          f\"Image AUROC: {r['image_AUROC']:.4f} | \"\n",
        "          f\"Image F1: {r['image_F1Score']:.4f} | \"\n",
        "          f\"Pixel AUROC: {r['pixel_AUROC']:.4f} | \"\n",
        "          f\"Pixel F1: {r['pixel_F1Score']:.4f} | \"\n",
        "          f\"Latency: {r['latency_sec']}s\")\n",
        "\n",
        "print(\"\\nAverage Metrics:\")\n",
        "for k, v in avg_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZD8xKR3RTYS"
      },
      "source": [
        "##EfficientAD S"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0m0ir-nQGl9"
      },
      "outputs": [],
      "source": [
        "MVTec = MVTecAD(\n",
        "    root = './datasets/MVTecAD',\n",
        "    category='bottle',\n",
        "    train_batch_size=1,\n",
        "    eval_batch_size=1,\n",
        "    num_workers=0)\n",
        "\n",
        "MVTec.prepare_data()\n",
        "MVTec.setup()\n",
        "\n",
        "model = EfficientAd()\n",
        "\n",
        "engine = Engine(\n",
        "    max_epochs = 10,\n",
        "    accelerator=\"auto\",  # \\<\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\">,\n",
        "    devices=1,\n",
        "    logger=False,\n",
        ")\n",
        "\n",
        "# Training\n",
        "start_time = time.time()\n",
        "engine.fit(model=model, datamodule=MVTec)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Testing\n",
        "start_time = time.time()\n",
        "test_result = engine.test(model=model, datamodule=MVTec)\n",
        "inference_time = time.time() - start_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB35KfYTQz_3",
        "outputId": "a6bf9a4c-194f-4321-be48-f64a24f4a5c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'image_AUROC': 1.0, 'image_F1Score': 0.9919999837875366, 'pixel_AUROC': 0.9697375893592834, 'pixel_F1Score': 0.7515456080436707}]\n"
          ]
        }
      ],
      "source": [
        "print(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_9fAOHlRHJo",
        "outputId": "b7dd9364-de15-416e-cbca-45d4d1e16f90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 542.5230667591095 seconds\n",
            "Inference time: 15.021449565887451 seconds\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training time: {training_time} seconds\")\n",
        "print(f\"Inference time: {inference_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Latency: {inference_time / len(MVTec.test_dataloader().dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne_13EdT9ilG",
        "outputId": "df85cb7e-149f-4dd2-dbc9-8c2de6d13993"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latency: 0.18098132007093315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZMD9EgSRbot"
      },
      "source": [
        "##EfficientAD M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD1AIGiUQ_RP"
      },
      "outputs": [],
      "source": [
        "MVTec = MVTecAD(\n",
        "    root = './datasets/MVTecAD',\n",
        "    category='bottle',\n",
        "    train_batch_size=1,\n",
        "    eval_batch_size=1,\n",
        "    num_workers=0)\n",
        "\n",
        "MVTec.prepare_data()\n",
        "MVTec.setup()\n",
        "\n",
        "model = EfficientAd(model_size = \"medium\")\n",
        "\n",
        "engine = Engine(\n",
        "    max_epochs = 10,\n",
        "    accelerator=\"auto\",  # \\<\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\">,\n",
        "    devices=1,\n",
        "    logger=False,\n",
        ")\n",
        "\n",
        "# Training\n",
        "start_time = time.time()\n",
        "engine.fit(model=model, datamodule=MVTec)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Testing\n",
        "start_time = time.time()\n",
        "test_result = engine.test(model=model, datamodule=MVTec)\n",
        "inference_time = time.time() - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JbDVAgHrRh5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67d08e9-1d1b-4fcb-dba5-4ca445cdfe2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'image_AUROC': 0.990476131439209, 'image_F1Score': 0.9599999785423279, 'pixel_AUROC': 0.9526698589324951, 'pixel_F1Score': 0.681119441986084}]\n"
          ]
        }
      ],
      "source": [
        "print(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "K0ruNVDhRiaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "560bdf14-11ed-47c9-b954-b6eb4a7940c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 1059.2677891254425 seconds\n",
            "Inference time: 19.093512773513794 seconds\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training time: {training_time} seconds\")\n",
        "print(f\"Inference time: {inference_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WyZORBpSlz8"
      },
      "source": [
        "##FastFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hEt1jna9T78A"
      },
      "outputs": [],
      "source": [
        "from anomalib.models import Fastflow\n",
        "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-ejT17QRpie"
      },
      "outputs": [],
      "source": [
        "datamodule = MVTecAD(\n",
        "    root='./datasets/MVTecAD',\n",
        "    category=\"bottle\",\n",
        "    train_batch_size=32,\n",
        "    eval_batch_size=32,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "datamodule.prepare_data()\n",
        "datamodule.setup()\n",
        "\n",
        "model = Fastflow(backbone=\"resnet18\", flow_steps=8)\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        mode=\"max\",\n",
        "        monitor=\"pixel_AUROC\",\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor=\"pixel_AUROC\",\n",
        "        mode=\"max\",\n",
        "        patience=3,\n",
        "    ),\n",
        "]\n",
        "\n",
        "engine = Engine(\n",
        "    callbacks=callbacks,\n",
        "    accelerator=\"auto\",  # \\<\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\">,\n",
        "    devices=1,\n",
        "    logger=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xzav9iY6SNeV"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "engine.fit(model=model, datamodule=datamodule)\n",
        "training_time = time.time() - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZZMz8BTSPoN"
      },
      "outputs": [],
      "source": [
        "# Testing\n",
        "start_time = time.time()\n",
        "test_results = engine.test(model=model, datamodule=datamodule)\n",
        "inference_time = time.time() - start_time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXzn3j9r3o_8",
        "outputId": "9d47f61c-cf31-482b-cb21-e5fe21616b2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'image_AUROC': 0.9992063641548157,\n",
              "  'image_F1Score': 0.9841269850730896,\n",
              "  'pixel_AUROC': 0.9734765291213989,\n",
              "  'pixel_F1Score': 0.6583619713783264}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MFfVWU8oSQ5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2524cfd-07d5-4859-d3a0-c46792132bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'image_AUROC': 0.9992063641548157, 'image_F1Score': 0.9841269850730896, 'pixel_AUROC': 0.9734765291213989, 'pixel_F1Score': 0.6583619713783264}]\n"
          ]
        }
      ],
      "source": [
        "print(test_results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training time: {training_time} seconds\")\n",
        "print(f\"Inference time: {inference_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcVDwzpY3rBa",
        "outputId": "48f7c493-f473-4985-cd58-2033628e296f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 223.50394463539124 seconds\n",
            "Inference time: 12.50313663482666 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Latency: {inference_time / len(datamodule.test_dataloader().dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHX1ivSW4nvc",
        "outputId": "4ead4f63-c053-4a9e-e86f-27d00a64c7f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latency: 0.1506402004195983\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}